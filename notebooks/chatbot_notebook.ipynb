{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ Chatbot_v2.ipynb\n",
    "\n",
    "## Description\n",
    "\n",
    "This notebook implements an improved multilingual chatbot using `facebook/blenderbot_small-90M` for dialogue and `persiannlp/mt5-small-parsinlu` models for translation. Improvements include better context handling, cleaner translations, and more natural responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1Ô∏è‚É£ Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch langdetect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2Ô∏è‚É£ Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BlenderbotSmallForConditionalGeneration, BlenderbotSmallTokenizer\n",
    "from transformers import MT5ForConditionalGeneration, MT5Tokenizer\n",
    "from langdetect import detect\n",
    "import torch, re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3Ô∏è‚É£ Load BlenderBot model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blender_model_name = 'facebook/blenderbot_small-90M'\n",
    "blender_tokenizer = BlenderbotSmallTokenizer.from_pretrained(blender_model_name)\n",
    "blender_model = BlenderbotSmallForConditionalGeneration.from_pretrained(blender_model_name)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "blender_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4Ô∏è‚É£ Load translation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_en_model_name = 'persiannlp/mt5-small-parsinlu-opus-translation_fa_en'\n",
    "en_fa_model_name = 'persiannlp/mt5-small-parsinlu-translation_en_fa'\n",
    "\n",
    "fa_en_tokenizer = MT5Tokenizer.from_pretrained(fa_en_model_name, legacy=False)\n",
    "fa_en_model = MT5ForConditionalGeneration.from_pretrained(fa_en_model_name)\n",
    "en_fa_tokenizer = MT5Tokenizer.from_pretrained(en_fa_model_name, legacy=False)\n",
    "en_fa_model = MT5ForConditionalGeneration.from_pretrained(en_fa_model_name)\n",
    "\n",
    "fa_en_model.to(device)\n",
    "en_fa_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5Ô∏è‚É£ Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return 'en'\n",
    "\n",
    "def clean_translation(text):\n",
    "    text = re.sub(r'⁄©ÿßÿ±ÿ®ÿ±[:Ôºö]\\s*', '', text)\n",
    "    text = re.sub(r'Bot[:Ôºö]\\s*', '', text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def translate_text(text, source_lang, target_lang):\n",
    "    if source_lang == target_lang:\n",
    "        return text\n",
    "\n",
    "    if source_lang == 'fa' and target_lang == 'en':\n",
    "        tokenizer, model = fa_en_tokenizer, fa_en_model\n",
    "    else:\n",
    "        tokenizer, model = en_fa_tokenizer, en_fa_model\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=512).to(device)\n",
    "    outputs = model.generate(**inputs, max_length=512, num_beams=4, early_stopping=True)\n",
    "    translated = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return clean_translation(translated)\n",
    "\n",
    "def generate_response(user_input, conversation_history):\n",
    "    input_lang = detect_language(user_input)\n",
    "    \n",
    "    if input_lang == 'fa':\n",
    "        input_text_en = translate_text(user_input, 'fa', 'en')\n",
    "    else:\n",
    "        input_text_en = user_input\n",
    "\n",
    "    conversation_history.append(f'User: {input_text_en}')\n",
    "    context = ' '.join(conversation_history[-4:])  # use last 4 messages for context\n",
    "\n",
    "    inputs = blender_tokenizer(context, return_tensors='pt', truncation=True, max_length=512).to(device)\n",
    "    reply_ids = blender_model.generate(\n",
    "        **inputs,\n",
    "        max_length=120,\n",
    "        num_beams=5,\n",
    "        no_repeat_ngram_size=3,\n",
    "        length_penalty=1.1,\n",
    "        top_p=0.9,\n",
    "        temperature=0.85,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    response_en = blender_tokenizer.decode(reply_ids[0], skip_special_tokens=True)\n",
    "    response_en = re.sub(r'User[:Ôºö]\\s*', '', response_en).strip()\n",
    "\n",
    "    if input_lang == 'fa':\n",
    "        response = translate_text(response_en, 'en', 'fa')\n",
    "    else:\n",
    "        response = response_en\n",
    "\n",
    "    conversation_history.append(f'Bot: {response_en}')\n",
    "    return response, conversation_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6Ô∏è‚É£ Test the improved chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_history = []\n",
    "\n",
    "print('üü¢ English Conversation Test:\\n')\n",
    "user_input = 'Hello! How are you today?'\n",
    "response, conversation_history = generate_response(user_input, conversation_history)\n",
    "print(f'User: {user_input}\\nBot: {response}\\n')\n",
    "\n",
    "user_input = 'What do you like to do for fun?'\n",
    "response, conversation_history = generate_response(user_input, conversation_history)\n",
    "print(f'User: {user_input}\\nBot: {response}\\n')\n",
    "\n",
    "print('üü£ Persian Conversation Test:\\n')\n",
    "user_input = 'ÿ≥ŸÑÿßŸÖ! ÿßŸÖÿ±Ÿàÿ≤ ⁄Üÿ∑Ÿàÿ± Ÿáÿ≥ÿ™€åÿü'\n",
    "response, conversation_history = generate_response(user_input, conversation_history)\n",
    "print(f'⁄©ÿßÿ±ÿ®ÿ±: {user_input}\\nÿ±ÿ®ÿßÿ™: {response}\\n')\n",
    "\n",
    "user_input = 'ÿ®ÿ±ÿß€å ÿ≥ÿ±⁄Øÿ±ŸÖ€å ⁄ÜŸá ⁄©ÿßÿ±Ÿáÿß€å€å ÿßŸÜÿ¨ÿßŸÖ ŸÖ€å‚ÄåÿØŸá€åÿü'\n",
    "response, conversation_history = generate_response(user_input, conversation_history)\n",
    "print(f'⁄©ÿßÿ±ÿ®ÿ±: {user_input}\\nÿ±ÿ®ÿßÿ™: {response}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
